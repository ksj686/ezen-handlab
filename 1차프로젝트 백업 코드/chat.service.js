/* ë¬´ë£Œë²„ì „ - credit ë„ˆë¬´ ì ìŒ
import OpenAI from "openai";

const client = new OpenAI({
  baseURL:
    "https://router.huggingface.co/hf-inference/models/CohereLabs/c4ai-command-r-plus-08-2024/v1", // âœ… Hugging Face Inference Router
  // "https://router.huggingface.co/nscale/v1",
  apiKey: process.env.HF_API_KEY, // ë°˜ë“œì‹œ .envì— HF í‚¤ ìˆì–´ì•¼ í•¨
});

let messageHistory = [
  {
    role: "system",
    content:
      "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¸í„°ë·° ì—°ìŠµ ì±—ë´‡ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ë¶€ë“œëŸ½ê²Œ ë‹µí•´ì£¼ì„¸ìš”. ì´ ì‚¬ì´íŠ¸ì˜ ê¸°ëŠ¥ì€ ì§ë¬´/ì¸ì„± ë©´ì ‘ì„ ë„ì™€ì¤˜ ì‚¬ìš©ìê°€ ë©´ì ‘ì— ìì‹ ê°ì„ ê°€ì§€ë„ë¡ ë„ì™€ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤. markdown ë¬¸ë²•ì€ ì ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ plaintextë¡œ ë‹µë³€í•˜ê¸°.",
  },
];

export const chatWithBot = async (userMessage) => {
  try {
    console.log(messageHistory);
    messageHistory.push({
      role: "user",
      content: userMessage,
    });

    const chatCompletion = await client.chat.completions.create({
      model: "CohereLabs/c4ai-command-r-plus-08-2024", // âœ… HFì—ì„œ ì œê³µí•˜ëŠ” OpenChat ëª¨ë¸
      // "Qwen/Qwen3-235B-A22B",
      messages: messageHistory,
    });

    const reply = chatCompletion.choices[0].message.content.trim();

    messageHistory.push({
      role: "assistant",
      content: reply,
    });

    return reply;
  } catch (error) {
    console.error("âŒ Hugging Face Chat í˜¸ì¶œ ì‹¤íŒ¨:", error.message);
    throw new Error("ì±—ë´‡ ì‘ë‹µ ì‹¤íŒ¨");
  }
};
*/

import OpenAI from "openai";

// ğŸ” OpenAI API í‚¤ëŠ” .envì— ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, // ë°˜ë“œì‹œ .envì— ìˆì–´ì•¼ í•¨
});

export const chatWithBot = async (userMessage) => {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content:
            "ë„ˆëŠ” ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì±—ë´‡ì´ì•¼. ì´ ì‚¬ì´íŠ¸ì˜ ê¸°ëŠ¥ì€ ì‚¬ìš©ìê°€ ì§ë¬´/ì¸ì„± ë©´ì ‘ ì¤€ë¹„ë¥¼ ì›í™œí•˜ê²Œ í•˜ë„ë¡ ë„ì™€ì¤˜. 100ì ì´ë‚´ë¡œ ë‹µë³€í•´ì¤˜.",
        },
        {
          role: "user",
          content: userMessage,
        },
      ],
    });

    const reply = response.choices[0]?.message?.content?.trim();

    return reply || "ì£„ì†¡í•´ìš”, ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆì–´ìš”.";
  } catch (error) {
    console.error("âŒ OpenAI Chat í˜¸ì¶œ ì‹¤íŒ¨:", error.message);
    throw new Error("ì±—ë´‡ ì‘ë‹µ ì‹¤íŒ¨");
  }
};

/* ì“¸ì¼ ì—†ì„ë“¯
import fetch from "node-fetch";

const HF_API_TOKEN = process.env.HF_API_KEY; // .envì— Hugging Face í‚¤ ì €ì¥

export const chatWithBot = async (message) => {
  const res = await fetch(
    "https://api-inference.huggingface.co/models/microsoft/DialoGPT-small", // ë˜ëŠ” mistralai/Mistral-7B-Instruct
    {
      method: "POST",
      headers: {
        Authorization: `Bearer ${HF_API_TOKEN}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        inputs: message,
      }),
    }
  );

  if (!res.ok) {
    const text = await res.text();
    console.error("ğŸ¤– HF ì‘ë‹µ ì˜¤ë¥˜:", res.status, text); // âœ… ì—ëŸ¬ ìƒì„¸ ì¶œë ¥
    throw new Error(`HF ì‘ë‹µ ì˜¤ë¥˜ (${res.status}): ${text}`);
  }

  const data = await res.json();
  return data.generated_text || "ì‘ë‹µ ì—†ìŒ";
};
*/
